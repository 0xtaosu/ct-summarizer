from flask import Flask, request, jsonify
import pandas as pd
from datetime import datetime, timedelta
import json
import threading
import queue
import logging
import os
import time
from openai import OpenAI
import schedule
from dotenv import load_dotenv
from telegram import Bot
import asyncio

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

app = Flask(__name__)

# åˆ›å»ºæ•°æ®é˜Ÿåˆ—
data_queue = queue.Queue()

# è®¾ç½®æ—¥å¿—é…ç½®
logging.basicConfig(
    filename='webhook.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

class TelegramBot:
    def __init__(self):
        self.token = os.getenv('TELEGRAM_BOT_TOKEN')
        self.chat_id = os.getenv('TELEGRAM_CHAT_ID')
        if not self.token or not self.chat_id:
            raise ValueError("TELEGRAM_BOT_TOKEN or TELEGRAM_CHAT_ID not found in environment variables")
        self.bot = Bot(token=self.token)
        # åˆ›å»ºäº‹ä»¶å¾ªç¯
        self.loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self.loop)
        
    async def send_message(self, text):
        """å‘é€æ¶ˆæ¯åˆ°Telegram"""
        try:
            await self.bot.send_message(
                chat_id=self.chat_id,
                text=text,
                parse_mode='MarkdownV2'  # æ”¹ç”¨ MarkdownV2
            )
            logging.info("Telegramæ¶ˆæ¯å‘é€æˆåŠŸ")
        except Exception as e:
            logging.error(f"å‘é€Telegramæ¶ˆæ¯å¤±è´¥: {str(e)}")

    def send_summary(self, period, summary):
        """
        å‘é€æ€»ç»“åˆ°Telegram
        ä½¿ç”¨Markdownæ ¼å¼åŒ–
        """
        # è½¬æ¢æ—¶é—´æ®µæ˜¾ç¤ºå’Œå¯¹åº”çš„emoji
        period_info = {
            '30min': ('30åˆ†é’Ÿ', 'â±ï¸'),
            '1hour': ('1å°æ—¶', 'ğŸ•'),
            '6hour': ('6å°æ—¶', 'â°')
        }.get(period, (period, 'ğŸ””'))
        
        period_display, emoji = period_info

        # è½¬ä¹‰Markdownç‰¹æ®Šå­—ç¬¦
        def escape_markdown(text):
            special_chars = ['_', '*', '[', ']', '(', ')', '~', '`', '>', '#', '+', '-', '=', '|', '{', '}', '.', '!']
            for char in special_chars:
                text = text.replace(char, f'\\{char}')
            return text

        # ä½¿ç”¨Markdownæ ¼å¼æ„å»ºæ¶ˆæ¯
        message = (
            f"{emoji} *Twitter {escape_markdown(period_display)}å¿«è®¯*\n\n"
            f"ğŸ“… åˆ†ææ—¶é—´: `{escape_markdown(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))} UTC`\n"
            f"ğŸ“Š åˆ†æèŒƒå›´: æœ€è¿‘{escape_markdown(period_display)}çš„æ•°æ®\n"
            f"{'_'*32}\n\n"
            f"*æ•°æ®åˆ†æ*\n"
            f"{escape_markdown(summary)}\n\n"
            f"{'_'*32}\n"
            f"ğŸ¤– ç”± DeepSeek AI æä¾›åˆ†ææ”¯æŒ"
        )
        
        try:
            future = asyncio.run_coroutine_threadsafe(
                self.send_message(message), 
                self.loop
            )
            future.result()
            logging.info(f"æˆåŠŸå‘é€{period_display}æ€»ç»“åˆ°Telegram")
        except Exception as e:
            logging.error(f"å‘é€{period_display}æ€»ç»“åˆ°Telegramå¤±è´¥: {str(e)}")

    def start(self):
        """å¯åŠ¨äº‹ä»¶å¾ªç¯"""
        def run_loop():
            self.loop.run_forever()
        
        # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œäº‹ä»¶å¾ªç¯
        threading.Thread(target=run_loop, daemon=True).start()

    def stop(self):
        """åœæ­¢äº‹ä»¶å¾ªç¯"""
        self.loop.call_soon_threadsafe(self.loop.stop)

class TwitterDataProcessor:
    """
    Twitteræ•°æ®å¤„ç†å™¨
    è´Ÿè´£æ•°æ®çš„å­˜å‚¨ã€éªŒè¯å’Œæ ¼å¼åŒ–
    """
    def __init__(self):
        # åˆå§‹åŒ–æ•°æ®ç›®å½•å’Œæ–‡ä»¶è·¯å¾„
        self.data_dir = "data"
        self.twitter_file = os.path.join(self.data_dir, "twitter_data.csv")
        os.makedirs(self.data_dir, exist_ok=True)
        
        # å®šä¹‰CSVæ–‡ä»¶åˆ—
        self.columns = [
            'timestamp',         # äº‹ä»¶å‘ç”Ÿæ—¶é—´
            'user_name',        # ç”¨æˆ·å
            'user_description', # ç”¨æˆ·ç®€ä»‹
            'event_type',       # äº‹ä»¶ç±»å‹
            'content'           # å†…å®¹
        ]
        
        # åˆå§‹åŒ–CSVæ–‡ä»¶
        self.init_csv_file()
        
    def init_csv_file(self):
        """åˆå§‹åŒ–æˆ–éªŒè¯CSVæ–‡ä»¶ç»“æ„"""
        # æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©ºæ—¶åˆ›å»ºæ–°æ–‡ä»¶
        if not os.path.exists(self.twitter_file) or os.path.getsize(self.twitter_file) == 0:
            pd.DataFrame(columns=self.columns).to_csv(self.twitter_file, index=False)
            return
            
        # éªŒè¯ç°æœ‰æ–‡ä»¶çš„åˆ—ç»“æ„
        try:
            df = pd.read_csv(self.twitter_file)
            if list(df.columns) != self.columns:
                # åˆ—ä¸åŒ¹é…æ—¶ï¼Œå¤‡ä»½æ—§æ–‡ä»¶å¹¶åˆ›å»ºæ–°æ–‡ä»¶
                backup_file = f"{self.twitter_file}.bak"
                os.rename(self.twitter_file, backup_file)
                logging.info(f"åˆ—ä¸åŒ¹é…ï¼Œå·²å¤‡ä»½æ—§æ–‡ä»¶åˆ°: {backup_file}")
                pd.DataFrame(columns=self.columns).to_csv(self.twitter_file, index=False)
        except Exception as e:
            logging.error(f"éªŒè¯CSVæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            pd.DataFrame(columns=self.columns).to_csv(self.twitter_file, index=False)
    
    def process_webhook_data(self, data):
        """
        å¤„ç†webhookæ¨é€çš„æ•°æ®
        Args:
            data: webhookæ¨é€çš„JSONæ•°æ®
        Returns:
            bool: å¤„ç†æ˜¯å¦æˆåŠŸ
        """
        try:
            # æå–åŸºæœ¬ä¿¡æ¯
            event_type = data.get('push_type', '')
            user_data = data.get('user', {})
            
            # æ„å»ºæ—¶é—´æˆ³
            timestamp = datetime.fromtimestamp(
                data.get('tweet', {}).get('publish_time') or 
                user_data.get('updated_at', time.time())
            ).isoformat()
            
            # æ„å»ºæ•°æ®è¡Œ
            row = {
                'timestamp': timestamp,
                'user_name': user_data.get('name', ''),
                'user_description': user_data.get('description', ''),
                'event_type': event_type,
                'content': (data.get('tweet', {}).get('text') or 
                           data.get('content', ''))
            }
            
            # ç¡®ä¿æ‰€æœ‰å¿…éœ€åˆ—éƒ½å­˜åœ¨
            for col in self.columns:
                if col not in row:
                    row[col] = ''
            
            # æŒ‰ç…§æŒ‡å®šåˆ—é¡ºåºæ’åˆ—æ•°æ®
            row = {col: row[col] for col in self.columns}
            
            # ä¿å­˜åˆ°CSVæ–‡ä»¶
            pd.DataFrame([row]).to_csv(self.twitter_file, mode='a', header=False, index=False)
            logging.info(f"æ•°æ®å·²ä¿å­˜ - äº‹ä»¶ç±»å‹: {event_type}")
            return True
            
        except Exception as e:
            logging.error(f"å¤„ç†æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            return False

class TwitterSummarizer:
    """
    Twitterå†…å®¹æ€»ç»“å™¨
    è´Ÿè´£ç”Ÿæˆå®šæœŸæ€»ç»“å¹¶é€šè¿‡Telegramå‘é€
    """
    def __init__(self):
        # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
        api_key = os.getenv('DEEPSEEK_API_KEY')
        if not api_key:
            raise ValueError("DEEPSEEK_API_KEY not found in environment variables")
            
        self.client = OpenAI(
            api_key=api_key,
            base_url="https://api.deepseek.com"
        )
        
        # åˆå§‹åŒ–æ—¶é—´è®°å½•
        self.last_summary_time = {
            '30min': datetime.now(),
            '1hour': datetime.now(),
            '6hour': datetime.now()
        }
        
        # åˆå§‹åŒ–Telegramæœºå™¨äºº
        try:
            self.telegram = TelegramBot()
            self.telegram.start()
        except Exception as e:
            logging.error(f"åˆå§‹åŒ–Telegram Botå¤±è´¥: {str(e)}")
            self.telegram = None
            
        # å¯åŠ¨å®šæ—¶ä»»åŠ¡
        self.start_scheduled_summaries()
    
    def get_period_data(self, period):
        """
        è·å–æŒ‡å®šæ—¶é—´æ®µçš„æ–°æ•°æ®
        Args:
            period: æ—¶é—´æ®µæ ‡è¯† ('30min', '1hour', '6hour')
        Returns:
            DataFrame: ç¬¦åˆæ—¶é—´æ¡ä»¶çš„æ•°æ®
        """
        now = datetime.now()
        # æ ¹æ®æ—¶é—´æ®µç¡®å®šæŸ¥è¯¢èŒƒå›´
        time_delta = {
            '30min': timedelta(minutes=30),
            '1hour': timedelta(hours=1),
            '6hour': timedelta(hours=6)
        }
        
        query_start = now - time_delta[period]
        
        try:
            df = pd.read_csv('data/twitter_data.csv')
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            # è·å–æ—¶é—´èŒƒå›´å†…çš„æ•°æ®
            new_data = df[df['timestamp'] > query_start]
            
            # æ›´æ–°æœ€åæ€»ç»“æ—¶é—´
            self.last_summary_time[period] = now
            
            return new_data
            
        except Exception as e:
            logging.error(f"è·å–{period}æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            return pd.DataFrame()

    def generate_summary(self, period):
        """ä½¿ç”¨ DeepSeek ç”Ÿæˆæ€»ç»“"""
        try:
            df = self.get_period_data(period)
            if len(df) == 0:
                return f"åœ¨è¿‡å»{period}å†…æ²¡æœ‰æ–°çš„æ¨æ–‡æ´»åŠ¨"

            events = df.to_dict('records')
            events_text = "\n".join([
                f"å‘å¸ƒè€…: {e['user_name']}\n"
                f"å‘å¸ƒè€…ç®€ä»‹: {e['user_description']}\n"
                f"äº‹ä»¶ç±»å‹: {e['event_type']}\n"
                f"å‘å¸ƒæ—¶é—´: {e['timestamp']}\n"
                f"å†…å®¹: {e['content']}\n"
                f"{'='*30}"
                for e in events
            ])

            system_prompt = """
ä½ çš„ç›®æ ‡æ˜¯åœ¨ç»™å®šçš„å†…å®¹ä¸­åˆ†æå¹¶æ‰¾åˆ°å½“å‰åŠ å¯†å¸‚åœºä¸­æœ€å…·ä»·å€¼ã€å…·æœ‰é•¿æœŸæŠ•èµ„æ½œåŠ›çš„å™äº‹å’Œé¡¹ç›®ã€‚é€šè¿‡å¤šç»´åº¦åˆ†æï¼Œå‰–æå¸‚åœºçƒ­ç‚¹ä¸å™äº‹èƒŒåçš„é€»è¾‘ï¼Œç­›é€‰å‡ºå€¼å¾—é•¿æœŸé‡ä»“çš„æ½œåŠ›é¡¹ç›®åŠå…¶æ”¯æŒçš„æ ¸å¿ƒç†å¿µã€‚

1. å‘å¸ƒè€…èƒŒæ™¯è¯„ä¼°ï¼š
- åˆ†æå‘å¸ƒè€…çš„èƒŒæ™¯ã€å½±å“åŠ›å’Œå¯ä¿¡åº¦
- è¯„ä¼°å…¶åœ¨åŠ å¯†å¸‚åœºä¸­çš„ä¸“ä¸šæ€§å’Œå£°èª‰

2. å†…å®¹åˆ†æï¼š
- æ£€æŸ¥æŠ€æœ¯ä¿¡æ¯çš„å¯éªŒè¯æ€§
- è¯„ä¼°é¡¹ç›®ç»†èŠ‚å’ŒæŠ€æœ¯å®ç°
- åˆ†æå¸‚åœºå‰ç»æ€§å’Œçƒ­é—¨è¶‹åŠ¿

å™äº‹èƒŒæ™¯åˆ†æï¼š
- æå–æ ¸å¿ƒå™äº‹ï¼ˆå¦‚AI Agentæ–°åœºæ™¯ã€æ•°æ®éšç§ç­‰ï¼‰
- è¯„ä¼°å™äº‹ä¸æŠ€æœ¯å‘å±•åŒ¹é…åº¦
- ç¡®å®šå™äº‹çš„åŸºç¡€æ¡†æ¶èƒ½åŠ›å’Œé€‚ç”¨æ€§

é•¿æœŸæ½œåŠ›è¯„ä¼°ï¼š
- æŠ€æœ¯æ”¯æŒï¼šè¯„ä¼°æŠ€æœ¯åŸºç¡€å’Œåˆ›æ–°æ€§
- ç»æµæ¨¡å‹ï¼šåˆ†æä»£å¸ç»æµå­¦å¯æŒç»­æ€§
- å¸‚åœºæ¥å—åº¦ï¼šè¯„ä¼°ç¤¾åŒºå…±è¯†åº¦

å‘å¸ƒè€…åŠç¤¾åŒºåˆ†æï¼š
- æ£€æŸ¥ç¤¾åŒºæ´»è·ƒåº¦å’Œç”Ÿæ€æ”¯æŒ
- å…³æ³¨æœºæ„èƒŒä¹¦å’ŒæŠ•èµ„äººæ”¯æŒ

æ•°æ®é©±åŠ¨è¯„ä¼°ï¼š
- åˆ†æç¤¾äº¤åª’ä½“äº’åŠ¨å’Œé“¾ä¸Šæ•°æ®
- è¯„ä¼°æƒ…ç»ªç¨³å®šæ€§
- è·Ÿè¸ªèµ„é‡‘æµå‘

é£é™©ä¸é•¿æœŸä»·å€¼åˆ†æï¼š
- è¯„ä¼°æŠ—é£é™©èƒ½åŠ›
- ç¡®å®šé•¿æœŸå‘å±•æ½œåŠ›

3. å¸‚åœºçƒ­åº¦åˆ†æï¼š
- è¯„ä¼°äº’åŠ¨æ•°æ®å’Œå¸‚åœºåå“
- åˆ†æç¤¾äº¤åª’ä½“æŒ‡æ ‡

4. æŠ•èµ„æ½œåŠ›è¯„ä¼°ï¼š
- ç»¼åˆè¯„åˆ†ï¼ˆ1-10åˆ†ï¼‰
- è€ƒè™‘å¤šç»´åº¦å› ç´ 

5. è¾“å‡ºæ ¼å¼ï¼š
- å±•ç¤ºå‰äº”åå†…å®¹å’ŒåŸå§‹é“¾æ¥
- è¯¦ç»†è¯´æ˜æŠ•èµ„æ½œåŠ›è¯„åˆ†
- æä¾›å…·ä½“çš„æ’åç†ç”±

è¯·ç”¨ä¸“ä¸šã€ç®€æ´çš„è¯­è¨€è¾“å‡ºåˆ†æç»“æœï¼Œé‡ç‚¹çªå‡ºé•¿æœŸæŠ•èµ„ä»·å€¼ã€‚
"""

            user_prompt = f"è¯·åˆ†æè¿‡å»{period}çš„ä»¥ä¸‹Twitteræ´»åŠ¨ï¼š\n{events_text}"

            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                stream=False
            )

            return response.choices[0].message.content

        except Exception as e:
            error_msg = f"ç”Ÿæˆ{period}æ€»ç»“æ—¶å‡ºé”™: {str(e)}"
            logging.error(error_msg)
            return error_msg

    def start_scheduled_summaries(self):
        """å¯åŠ¨å®šæ—¶æ€»ç»“ä»»åŠ¡"""
        def run_schedule():
            while True:
                schedule.run_pending()
                time.sleep(1)

        def generate_and_send_summary(period):
            """ç”Ÿæˆå¹¶å‘é€æ€»ç»“"""
            summary = self.generate_summary(period)
            # æ‰“å°åˆ°æ§åˆ¶å°
            print(f"\n=== {period} å®šæ—¶æ€»ç»“ ===")
            print(f"æ€»ç»“æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} UTC")
            print(summary)
            print("="*50)
            
            # å‘é€åˆ°Telegram
            if self.telegram:
                self.telegram.send_summary(period, summary)

        # è®¾ç½®å®šæ—¶ä»»åŠ¡ (UTCæ—¶é—´)
        schedule.every(30).minutes.do(lambda: generate_and_send_summary('30min'))
        schedule.every(1).hour.do(lambda: generate_and_send_summary('1hour'))
        schedule.every(6).hours.do(lambda: generate_and_send_summary('6hour'))

        # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œå®šæ—¶ä»»åŠ¡
        threading.Thread(target=run_schedule, daemon=True).start()
        logging.info("å®šæ—¶æ€»ç»“ä»»åŠ¡å·²å¯åŠ¨ (UTC)")

# åˆ›å»ºå¤„ç†å™¨å®ä¾‹
data_processor = TwitterDataProcessor()

@app.route('/webhook/twitter', methods=['POST'])
def webhook_receiver():
    """æ¥æ”¶webhookæ¨é€çš„æ•°æ®å¹¶å¤„ç†"""
    try:
        logging.info("=== æ”¶åˆ°æ–°çš„ Webhook è¯·æ±‚ ===")
        logging.info(f"è¯·æ±‚æ–¹æ³•: {request.method}")
        logging.info(f"è¯·æ±‚å¤´: {dict(request.headers)}")
        logging.info(f"JSON æ•°æ®: {request.json}")
        
        if data_processor.process_webhook_data(request.json):
            return jsonify({
                "status": "success",
                "message": "Data processed and saved",
                "timestamp": datetime.now().isoformat()
            }), 200
        else:
            return jsonify({
                "status": "error",
                "message": "Failed to process data"
            }), 500
            
    except Exception as e:
        logging.error(f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return jsonify({
            "status": "error",
            "message": str(e)
        }), 500

def process_data():
    """å¤„ç†é˜Ÿåˆ—ä¸­çš„æ•°æ®"""
    try:
        summarizer = TwitterSummarizer()
        
        while True:
            try:
                # ä»é˜Ÿåˆ—ä¸­è·å–æ•°æ®
                data = data_queue.get()
                # ä¿å­˜æ•°æ®
                data_processor.process_webhook_data(data)
                
            except Exception as e:
                logging.error(f"å¤„ç†æ•°æ®å¤±è´¥: {str(e)}")
    except Exception as e:
        logging.error(f"åˆå§‹åŒ– TwitterSummarizer å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    # åˆ›å»ºå¹¶å¯åŠ¨æ•°æ®å¤„ç†çº¿ç¨‹
    process_thread = threading.Thread(target=process_data)
    process_thread.daemon = True
    process_thread.start()
    
    # å¯åŠ¨FlaskæœåŠ¡å™¨
    app.run(host='0.0.0.0', port=5000)