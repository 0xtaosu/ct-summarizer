from flask import Flask, request, jsonify
import pandas as pd
from datetime import datetime, timedelta
import json
import threading
import queue
import logging
import os
import time
from openai import OpenAI
import schedule
from dotenv import load_dotenv
from telegram import Bot
import asyncio

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

app = Flask(__name__)

# åˆ›å»ºæ•°æ®é˜Ÿåˆ—
data_queue = queue.Queue()

# è®¾ç½®æ—¥å¿—é…ç½®
logging.basicConfig(
    filename='webhook.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

class TelegramBot:
    def __init__(self):
        self.token = os.getenv('TELEGRAM_BOT_TOKEN')
        self.chat_id = os.getenv('TELEGRAM_CHAT_ID')
        if not self.token or not self.chat_id:
            raise ValueError("TELEGRAM_BOT_TOKEN or TELEGRAM_CHAT_ID not found in environment variables")
        self.bot = Bot(token=self.token)
        # åˆ›å»ºäº‹ä»¶å¾ªç¯
        self.loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self.loop)
        
    async def send_message(self, text):
        """å‘é€æ¶ˆæ¯åˆ°Telegramï¼Œä½¿ç”¨HTMLæ ¼å¼"""
        try:
            await self.bot.send_message(
                chat_id=self.chat_id,
                text=text,
                parse_mode='HTML'  # ä½¿ç”¨HTMLæ ¼å¼
            )
            logging.info("Telegramæ¶ˆæ¯å‘é€æˆåŠŸ")
        except Exception as e:
            logging.error(f"å‘é€Telegramæ¶ˆæ¯å¤±è´¥: {str(e)}")

    def send_summary(self, period, summary):
        """
        å‘é€æ€»ç»“åˆ°Telegram
        ç›´æ¥ä½¿ç”¨HTMLæ ¼å¼
        """
        period_info = {
            '1hour': ('1å°æ—¶', 'ğŸ•')
        }.get(period, (period, 'ğŸ””'))
        
        period_display, emoji = period_info

        # æ„å»ºæ¶ˆæ¯
        message = (
            f"{emoji} <b>Twitter {period_display}å¿«è®¯</b>\n\n"
            f"ğŸ“… åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} UTC\n"
            f"ğŸ“Š åˆ†æèŒƒå›´: æœ€è¿‘{period_display}çš„æ•°æ®\n"
            f"{'â€”'*32}\n\n"
            f"{summary}\n\n"  # ç›´æ¥ä½¿ç”¨summaryï¼Œå› ä¸ºå·²ç»æ˜¯HTMLæ ¼å¼
            f"{'â€”'*32}\n"
            f"ğŸ¤– ç”± DeepSeek AI æä¾›åˆ†ææ”¯æŒ"
        )
        
        try:
            future = asyncio.run_coroutine_threadsafe(
                self.send_message(message), 
                self.loop
            )
            future.result()
            logging.info(f"æˆåŠŸå‘é€{period_display}æ€»ç»“åˆ°Telegram")
        except Exception as e:
            logging.error(f"å‘é€{period_display}æ€»ç»“åˆ°Telegramå¤±è´¥: {str(e)}")

    def start(self):
        """å¯åŠ¨äº‹ä»¶å¾ªç¯"""
        def run_loop():
            self.loop.run_forever()
        
        # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œäº‹ä»¶å¾ªç¯
        threading.Thread(target=run_loop, daemon=True).start()

    def stop(self):
        """åœæ­¢äº‹ä»¶å¾ªç¯"""
        self.loop.call_soon_threadsafe(self.loop.stop)

class TwitterDataProcessor:
    """
    Twitteræ•°æ®å¤„ç†å™¨
    è´Ÿè´£æ•°æ®çš„å­˜å‚¨ã€éªŒè¯å’Œæ ¼å¼åŒ–
    """
    def __init__(self):
        # åˆå§‹åŒ–æ•°æ®ç›®å½•å’Œæ–‡ä»¶è·¯å¾„
        self.data_dir = "data"
        self.twitter_file = os.path.join(self.data_dir, "twitter_data.csv")
        os.makedirs(self.data_dir, exist_ok=True)
        
        # å®šä¹‰CSVæ–‡ä»¶åˆ—
        self.columns = [
            'timestamp',         # äº‹ä»¶å‘ç”Ÿæ—¶é—´
            'user_name',        # ç”¨æˆ·å
            'user_description', # ç”¨æˆ·ç®€ä»‹
            'event_type',       # äº‹ä»¶ç±»å‹
            'content'           # å†…å®¹
        ]
        
        # åˆå§‹åŒ–CSVæ–‡ä»¶
        self.init_csv_file()
        
    def init_csv_file(self):
        """åˆå§‹åŒ–æˆ–éªŒè¯CSVæ–‡ä»¶ç»“æ„"""
        # æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©ºæ—¶åˆ›å»ºæ–°æ–‡ä»¶
        if not os.path.exists(self.twitter_file) or os.path.getsize(self.twitter_file) == 0:
            pd.DataFrame(columns=self.columns).to_csv(self.twitter_file, index=False)
            return
            
        # éªŒè¯ç°æœ‰æ–‡ä»¶çš„åˆ—ç»“æ„
        try:
            df = pd.read_csv(self.twitter_file)
            if list(df.columns) != self.columns:
                # åˆ—ä¸åŒ¹é…æ—¶ï¼Œå¤‡ä»½æ—§æ–‡ä»¶å¹¶åˆ›å»ºæ–°æ–‡ä»¶
                backup_file = f"{self.twitter_file}.bak"
                os.rename(self.twitter_file, backup_file)
                logging.info(f"åˆ—ä¸åŒ¹é…ï¼Œå·²å¤‡ä»½æ—§æ–‡ä»¶åˆ°: {backup_file}")
                pd.DataFrame(columns=self.columns).to_csv(self.twitter_file, index=False)
        except Exception as e:
            logging.error(f"éªŒè¯CSVæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            pd.DataFrame(columns=self.columns).to_csv(self.twitter_file, index=False)
    
    def process_webhook_data(self, data):
        """
        å¤„ç†webhookæ¨é€çš„æ•°æ®
        Args:
            data: webhookæ¨é€çš„JSONæ•°æ®
        Returns:
            bool: å¤„ç†æ˜¯å¦æˆåŠŸ
        """
        try:
            # æå–åŸºæœ¬ä¿¡æ¯
            event_type = data.get('push_type', '')
            user_data = data.get('user', {})
            
            # æ„å»ºæ—¶é—´æˆ³
            timestamp = datetime.fromtimestamp(
                data.get('tweet', {}).get('publish_time') or 
                user_data.get('updated_at', time.time())
            ).isoformat()
            
            # æ„å»ºæ•°æ®è¡Œ
            row = {
                'timestamp': timestamp,
                'user_name': user_data.get('name', ''),
                'user_description': user_data.get('description', ''),
                'event_type': event_type,
                'content': (data.get('tweet', {}).get('text') or 
                           data.get('content', ''))
            }
            
            # ç¡®ä¿æ‰€æœ‰å¿…éœ€åˆ—éƒ½å­˜åœ¨
            for col in self.columns:
                if col not in row:
                    row[col] = ''
            
            # æŒ‰ç…§æŒ‡å®šåˆ—é¡ºåºæ’åˆ—æ•°æ®
            row = {col: row[col] for col in self.columns}
            
            # ä¿å­˜åˆ°CSVæ–‡ä»¶
            pd.DataFrame([row]).to_csv(self.twitter_file, mode='a', header=False, index=False)
            logging.info(f"æ•°æ®å·²ä¿å­˜ - äº‹ä»¶ç±»å‹: {event_type}")
            return True
            
        except Exception as e:
            logging.error(f"å¤„ç†æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            return False

class TwitterSummarizer:
    """
    Twitterå†…å®¹æ€»ç»“å™¨
    è´Ÿè´£ç”Ÿæˆå®šæœŸæ€»ç»“å¹¶é€šè¿‡Telegramå‘é€
    """
    def __init__(self):
        # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
        api_key = os.getenv('DEEPSEEK_API_KEY')
        if not api_key:
            raise ValueError("DEEPSEEK_API_KEY not found in environment variables")
            
        self.client = OpenAI(
            api_key=api_key,
            base_url="https://api.deepseek.com"
        )
        
        # åˆå§‹åŒ–æ—¶é—´è®°å½•
        self.last_summary_time = {
            '1hour': datetime.now()
        }
        
        # åˆå§‹åŒ–Telegramæœºå™¨äºº
        try:
            self.telegram = TelegramBot()
            self.telegram.start()
        except Exception as e:
            logging.error(f"åˆå§‹åŒ–Telegram Botå¤±è´¥: {str(e)}")
            self.telegram = None
            
        # å¯åŠ¨å®šæ—¶ä»»åŠ¡
        self.start_scheduled_summaries()
    
    def get_period_data(self, period):
        """
        è·å–æŒ‡å®šæ—¶é—´æ®µçš„æ–°æ•°æ®
        Args:
            period: æ—¶é—´æ®µæ ‡è¯† ('1hour')
        Returns:
            DataFrame: ç¬¦åˆæ—¶é—´æ¡ä»¶çš„æ•°æ®
        """
        now = datetime.now()
        # åªä¿ç•™1å°æ—¶çš„æ—¶é—´æ®µå®šä¹‰
        time_delta = {
            '1hour': timedelta(hours=1)
        }
        
        query_start = now - time_delta[period]
        
        try:
            df = pd.read_csv('data/twitter_data.csv')
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            new_data = df[df['timestamp'] > query_start]
            
            self.last_summary_time[period] = now
            return new_data
            
        except Exception as e:
            logging.error(f"è·å–{period}æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            return pd.DataFrame()

    def generate_summary(self, period):
        """ä½¿ç”¨ DeepSeek ç”Ÿæˆæ€»ç»“"""
        try:
            df = self.get_period_data(period)
            if len(df) == 0:
                return f"åœ¨è¿‡å»{period}å†…æ²¡æœ‰æ–°çš„æ¨æ–‡æ´»åŠ¨"

            events = df.to_dict('records')
            events_text = "\n".join([
                f"å‘å¸ƒè€…: {e['user_name']}\n"
                f"å‘å¸ƒè€…ç®€ä»‹: {e['user_description']}\n"
                f"äº‹ä»¶ç±»å‹: {e['event_type']}\n"
                f"å‘å¸ƒæ—¶é—´: {e['timestamp']}\n"
                f"å†…å®¹: {e['content']}\n"
                f"{'='*30}"
                for e in events
            ])

            system_prompt = """
ç›®æ ‡ï¼šæ€»ç»“æŒ‡å®šæ—¶é—´æ®µå†…çš„æ–°é—»å†…å®¹ï¼Œæå–å…³é”®äº‹ä»¶ï¼Œè¯†åˆ«æ¶‰åŠçš„ä»£å¸æˆ–é¡¹ç›®ï¼Œå¹¶ç»“åˆç¤¾äº¤åª’ä½“æ•°æ®æä¾›ä¸Šä¸‹æ–‡å’Œç›¸å…³è¯¦ç»†ä¿¡æ¯ã€‚è¾“å‡ºéœ€é‡‡ç”¨ HTML æ ¼å¼ï¼Œé€‚é… Telegram æ¶ˆæ¯å±•ç¤ºã€‚

åˆ†ææ­¥éª¤ï¼š
1. æ–°é—»äº‹ä»¶æ€»ç»“ï¼š
- æå–è¿‡å»æŒ‡å®šæ—¶é—´æ®µå†…çš„æ‰€æœ‰å…³é”®æ–°é—»äº‹ä»¶
- æŒ‰ä¸»é¢˜åˆ†ç±»ï¼ˆå¸‚åœºè¶‹åŠ¿/æŠ€æœ¯çªç ´/æ”¿ç­–åŠ¨æ€/çªå‘æ–°é—»ï¼‰
- ç®€æ´æ˜äº†åœ°æ¦‚è¿°æ¯ä¸ªäº‹ä»¶çš„æ ¸å¿ƒä¿¡æ¯

2. ä»£å¸æˆ–é¡¹ç›®æå–ï¼š
- ä»æ–°é—»å†…å®¹ä¸­è¯†åˆ«å¹¶æå–ä»»ä½•æåˆ°çš„ä»£å¸åç§°æˆ–é¡¹ç›®
- éªŒè¯ä»£å¸æˆ–é¡¹ç›®çš„å¯ä¿¡åº¦ï¼Œä¾‹å¦‚æ˜¯å¦è·å¾—è¡Œä¸šè®¤å¯æˆ–å…·æœ‰æ˜ç¡®é“¾ä¸Šè®°å½•

3. è¡¥å……ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
- æä¾›ä»£å¸æˆ–é¡¹ç›®çš„èƒŒæ™¯èµ„æ–™ï¼Œä¾‹å¦‚æŠ€æœ¯ç‰¹ç‚¹ã€å›¢é˜Ÿä»‹ç»ã€ä»£å¸ç»æµæ¨¡å‹
- åˆ†ææ–°é—»ä¸­æåŠçš„ä»£å¸æˆ–é¡¹ç›®ä¸äº‹ä»¶ä¹‹é—´çš„å…³ç³»
- æ•´åˆç›¸å…³çš„ç¤¾äº¤åª’ä½“æ•°æ®ï¼Œä¾‹å¦‚ Twitter é“¾æ¥å’Œç¤¾åŒºè®¨è®ºå†…å®¹

è¯·æŒ‰ä»¥ä¸‹HTMLæ ¼å¼è¾“å‡ºï¼š

<b>ğŸ˜Š å¸‚åœºåŠ¨æ€</b>
- [ç®€è¦æ¦‚è¿°å…³é”®å¸‚åœºäº‹ä»¶]

<b>ğŸ”¥ çƒ­é—¨ä»£å¸/é¡¹ç›®åˆ†æ</b>

<b>1. [ä»£å¸/é¡¹ç›®åç§°]</b>
- <b>æ ¸å¿ƒå†…å®¹ï¼š</b> [ç®€è¦æè¿°ä»£å¸/é¡¹ç›®çš„ä¸»è¦æ–°é—»]
- <b>å¸‚åœºåå“ï¼š</b>
  - <i>è®¨è®ºèšç„¦ï¼š</i> [å›´ç»•è¯¥ä»£å¸/é¡¹ç›®çš„ä¸»è¦è¯é¢˜]
  - <i>ç¤¾åŒºæƒ…ç»ªï¼š</i> [æƒ…ç»ªåˆ†æ]
- <b>ç›¸å…³æ–°é—»é“¾æ¥ï¼š</b>
  - <a href="é“¾æ¥1">[Twitteré“¾æ¥æè¿°1]</a>
  - <a href="é“¾æ¥2">[Twitteré“¾æ¥æè¿°2]</a>

<b>2. [ä»£å¸/é¡¹ç›®åç§°]</b>
- <b>æ ¸å¿ƒå†…å®¹ï¼š</b> [ç®€è¦æè¿°]
- <b>å¸‚åœºåå“ï¼š</b>
  - <i>è®¨è®ºèšç„¦ï¼š</i> [ä¸»è¦è¯é¢˜]
  - <i>ç¤¾åŒºæƒ…ç»ªï¼š</i> [æƒ…ç»ªåˆ†æ]
- <b>ç›¸å…³æ–°é—»é“¾æ¥ï¼š</b>
  - <a href="é“¾æ¥1">[Twitteré“¾æ¥æè¿°1]</a>
  - <a href="é“¾æ¥2">[Twitteré“¾æ¥æè¿°2]</a>

æ³¨æ„ï¼š
1. ç¡®ä¿æ‰€æœ‰HTMLæ ‡ç­¾æ­£ç¡®é—­åˆ
2. ä¿æŒæ ¼å¼ç»Ÿä¸€æ€§
3. é“¾æ¥éœ€è¦æ˜¯å®Œæ•´çš„URL
4. å†…å®¹åº”è¯¥ç®€æ´æ˜äº†ï¼Œé‡ç‚¹çªå‡º
"""

            user_prompt = f"è¯·åˆ†æè¿‡å»{period}çš„ä»¥ä¸‹Twitteræ´»åŠ¨ï¼š\n{events_text}"

            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                stream=False
            )

            return response.choices[0].message.content

        except Exception as e:
            error_msg = f"ç”Ÿæˆ{period}æ€»ç»“æ—¶å‡ºé”™: {str(e)}"
            logging.error(error_msg)
            return error_msg

    def start_scheduled_summaries(self):
        """å¯åŠ¨å®šæ—¶æ€»ç»“ä»»åŠ¡"""
        def run_schedule():
            while True:
                schedule.run_pending()
                time.sleep(1)

        def generate_and_send_summary(period):
            """ç”Ÿæˆå¹¶å‘é€æ€»ç»“"""
            summary = self.generate_summary(period)
            # æ‰“å°åˆ°æ§åˆ¶å°
            print(f"\n=== {period} å®šæ—¶æ€»ç»“ ===")
            print(f"æ€»ç»“æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} UTC")
            print(summary)
            print("="*50)
            
            # å‘é€åˆ°Telegram
            if self.telegram:
                self.telegram.send_summary(period, summary)

        # åªä¿ç•™1å°æ—¶çš„å®šæ—¶ä»»åŠ¡
        schedule.every(1).hour.do(lambda: generate_and_send_summary('1hour'))

        # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œå®šæ—¶ä»»åŠ¡
        threading.Thread(target=run_schedule, daemon=True).start()
        logging.info("å®šæ—¶æ€»ç»“ä»»åŠ¡å·²å¯åŠ¨ (UTC)")

# åˆ›å»ºå¤„ç†å™¨å®ä¾‹
data_processor = TwitterDataProcessor()

@app.route('/webhook/twitter', methods=['POST'])
def webhook_receiver():
    """æ¥æ”¶webhookæ¨é€çš„æ•°æ®å¹¶å¤„ç†"""
    try:
        logging.info("=== æ”¶åˆ°æ–°çš„ Webhook è¯·æ±‚ ===")
        logging.info(f"è¯·æ±‚æ–¹æ³•: {request.method}")
        logging.info(f"è¯·æ±‚å¤´: {dict(request.headers)}")
        logging.info(f"JSON æ•°æ®: {request.json}")
        
        if data_processor.process_webhook_data(request.json):
            return jsonify({
                "status": "success",
                "message": "Data processed and saved",
                "timestamp": datetime.now().isoformat()
            }), 200
        else:
            return jsonify({
                "status": "error",
                "message": "Failed to process data"
            }), 500
            
    except Exception as e:
        logging.error(f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return jsonify({
            "status": "error",
            "message": str(e)
        }), 500

def process_data():
    """å¤„ç†é˜Ÿåˆ—ä¸­çš„æ•°æ®"""
    try:
        summarizer = TwitterSummarizer()
        
        while True:
            try:
                # ä»é˜Ÿåˆ—ä¸­è·å–æ•°æ®
                data = data_queue.get()
                # ä¿å­˜æ•°æ®
                data_processor.process_webhook_data(data)
                
            except Exception as e:
                logging.error(f"å¤„ç†æ•°æ®å¤±è´¥: {str(e)}")
    except Exception as e:
        logging.error(f"åˆå§‹åŒ– TwitterSummarizer å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    # åˆ›å»ºå¹¶å¯åŠ¨æ•°æ®å¤„ç†çº¿ç¨‹
    process_thread = threading.Thread(target=process_data)
    process_thread.daemon = True
    process_thread.start()
    
    # å¯åŠ¨FlaskæœåŠ¡å™¨
    app.run(host='0.0.0.0', port=5000)