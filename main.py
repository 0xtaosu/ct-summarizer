from flask import Flask, request, jsonify
import pandas as pd
from datetime import datetime
import json
import threading
import queue
import logging
import os
import time
from openai import OpenAI
import schedule
from dotenv import load_dotenv
from telegram import Bot
import asyncio

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

app = Flask(__name__)

# åˆ›å»ºæ•°æ®é˜Ÿåˆ—
data_queue = queue.Queue()

# è®¾ç½®æ—¥å¿—é…ç½®
logging.basicConfig(
    filename='webhook.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

class TelegramBot:
    def __init__(self):
        self.token = os.getenv('TELEGRAM_BOT_TOKEN')
        self.chat_id = os.getenv('TELEGRAM_CHAT_ID')
        if not self.token or not self.chat_id:
            raise ValueError("TELEGRAM_BOT_TOKEN or TELEGRAM_CHAT_ID not found in environment variables")
        self.bot = Bot(token=self.token)
        # åˆ›å»ºäº‹ä»¶å¾ªç¯
        self.loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self.loop)
        
    async def send_message(self, text):
        """å‘é€æ¶ˆæ¯åˆ°Telegram"""
        try:
            await self.bot.send_message(
                chat_id=self.chat_id,
                text=text,
                parse_mode='HTML'
            )
            logging.info("Telegramæ¶ˆæ¯å‘é€æˆåŠŸ")
        except Exception as e:
            logging.error(f"å‘é€Telegramæ¶ˆæ¯å¤±è´¥: {str(e)}")

    def send_summary(self, period, summary):
        """å‘é€æ€»ç»“åˆ°Telegram"""
        # è½¬æ¢æ—¶é—´æ®µæ˜¾ç¤º
        period_display = {
            '30min': '30åˆ†é’Ÿ',
            '6hour': '6å°æ—¶',
            '24hour': '24å°æ—¶'
        }.get(period, period)

        # æ·»åŠ è¡¨æƒ…ç¬¦å·å¢åŠ å¯è¯»æ€§
        message = (
            f"ğŸ”” <b>Twitter {period_display}æ•°æ®åˆ†æ</b>\n\n"
            f"â° åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} UTC\n"
            f"{'â”€'*32}\n\n"
            f"ğŸ“Š <b>æ•°æ®æ€»ç»“</b>\n"
            f"{summary}\n\n"
            f"{'â”€'*32}\n"
            f"ğŸ¤– ç”± DeepSeek AI æä¾›åˆ†ææ”¯æŒ"
        )
        
        try:
            # åœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥å‘é€
            future = asyncio.run_coroutine_threadsafe(
                self.send_message(message), 
                self.loop
            )
            future.result()  # ç­‰å¾…å‘é€å®Œæˆ
            logging.info(f"æˆåŠŸå‘é€{period_display}æ€»ç»“åˆ°Telegram")
        except Exception as e:
            logging.error(f"å‘é€{period_display}æ€»ç»“åˆ°Telegramå¤±è´¥: {str(e)}")

    def start(self):
        """å¯åŠ¨äº‹ä»¶å¾ªç¯"""
        def run_loop():
            self.loop.run_forever()
        
        # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œäº‹ä»¶å¾ªç¯
        threading.Thread(target=run_loop, daemon=True).start()

    def stop(self):
        """åœæ­¢äº‹ä»¶å¾ªç¯"""
        self.loop.call_soon_threadsafe(self.loop.stop)

class TwitterDataProcessor:
    def __init__(self):
        self.data_dir = "data"
        self.twitter_file = os.path.join(self.data_dir, "twitter_data.csv")
        os.makedirs(self.data_dir, exist_ok=True)
        self.init_csv_file()
        
    def init_csv_file(self):
        """åˆå§‹åŒ–CSVæ–‡ä»¶å’Œåˆ—"""
        self.columns = [
            'timestamp',         # äº‹ä»¶å‘ç”Ÿæ—¶é—´
            'user_name',        # ç”¨æˆ·å
            'user_description', # ç”¨æˆ·ç®€ä»‹
            'event_type',       # äº‹ä»¶ç±»å‹
            'content'           # å†…å®¹
        ]
        
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œåˆ›å»ºæ–°æ–‡ä»¶
        if not os.path.exists(self.twitter_file) or os.path.getsize(self.twitter_file) == 0:
            pd.DataFrame(columns=self.columns).to_csv(self.twitter_file, index=False)
        else:
            # éªŒè¯ç°æœ‰æ–‡ä»¶çš„åˆ—
            try:
                df = pd.read_csv(self.twitter_file)
                if list(df.columns) != self.columns:
                    # å¤‡ä»½æ—§æ–‡ä»¶
                    backup_file = f"{self.twitter_file}.bak"
                    os.rename(self.twitter_file, backup_file)
                    logging.info(f"åˆ—ä¸åŒ¹é…ï¼Œå·²å¤‡ä»½æ—§æ–‡ä»¶åˆ°: {backup_file}")
                    # åˆ›å»ºæ–°æ–‡ä»¶
                    pd.DataFrame(columns=self.columns).to_csv(self.twitter_file, index=False)
            except Exception as e:
                logging.error(f"éªŒè¯CSVæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
                # åˆ›å»ºæ–°æ–‡ä»¶
                pd.DataFrame(columns=self.columns).to_csv(self.twitter_file, index=False)
    
    def process_webhook_data(self, data):
        """å¤„ç†webhookæ•°æ®"""
        try:
            event_type = data.get('push_type', '')
            user_data = data.get('user', {})
            
            # è·å–äº‹ä»¶æ—¶é—´
            timestamp = datetime.fromtimestamp(
                data.get('tweet', {}).get('publish_time') or 
                user_data.get('updated_at', time.time())
            ).isoformat()
            
            # è·å–ç”¨æˆ·ç®€ä»‹
            user_description = user_data.get('description', '')
            
            # è·å–å†…å®¹
            content = (data.get('tweet', {}).get('text') or 
                      data.get('content', ''))
            
            # æ„å»ºè¡Œæ•°æ®
            row = {
                'timestamp': timestamp,
                'user_name': user_data.get('name', ''),
                'user_description': user_description,
                'event_type': event_type,
                'content': content
            }
            
            # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨
            for col in self.columns:
                if col not in row:
                    row[col] = ''
            
            # æŒ‰ç…§æŒ‡å®šåˆ—é¡ºåºæ’åˆ—æ•°æ®
            row = {col: row[col] for col in self.columns}
            
            # ä¿å­˜åˆ°CSV
            pd.DataFrame([row]).to_csv(self.twitter_file, mode='a', header=False, index=False)
            logging.info(f"æ•°æ®å·²ä¿å­˜ - äº‹ä»¶ç±»å‹: {event_type}")
            return True
            
        except Exception as e:
            logging.error(f"å¤„ç†æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            return False

class TwitterSummarizer:
    def __init__(self):
        api_key = os.getenv('DEEPSEEK_API_KEY')
        if not api_key:
            raise ValueError("DEEPSEEK_API_KEY not found in environment variables")
            
        self.client = OpenAI(
            api_key=api_key,
            base_url="https://api.deepseek.com"
        )
        self.last_summary_time = {
            '30min': datetime.now(),
            '6hour': datetime.now(),
            '24hour': datetime.now()
        }
        # åˆå§‹åŒ–Telegram bot
        try:
            self.telegram = TelegramBot()
            self.telegram.start()
        except Exception as e:
            logging.error(f"åˆå§‹åŒ–Telegram Botå¤±è´¥: {str(e)}")
            self.telegram = None
            
        self.start_scheduled_summaries()
    
    def get_period_data(self, period):
        """è·å–æŒ‡å®šæ—¶é—´æ®µçš„æ–°æ•°æ®"""
        now = datetime.now()
        last_time = self.last_summary_time[period]
        
        try:
            df = pd.read_csv('data/twitter_data.csv')
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            new_data = df[df['timestamp'] > last_time]
            
            # æ›´æ–°æœ€åæ€»ç»“æ—¶é—´
            self.last_summary_time[period] = now
            
            return new_data
            
        except Exception as e:
            logging.error(f"è·å–{period}æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            return pd.DataFrame()

    def generate_summary(self, period):
        """ä½¿ç”¨ DeepSeek ç”Ÿæˆæ€»ç»“"""
        try:
            df = self.get_period_data(period)
            if len(df) == 0:
                return f"åœ¨è¿‡å»{period}å†…æ²¡æœ‰æ–°çš„æ¨æ–‡æ´»åŠ¨"

            events = df.to_dict('records')
            events_text = "\n".join([
                f"å‘å¸ƒè€…: {e['user_name']}\n"
                f"å‘å¸ƒè€…ç®€ä»‹: {e['user_description']}\n"
                f"äº‹ä»¶ç±»å‹: {e['event_type']}\n"
                f"å‘å¸ƒæ—¶é—´: {e['timestamp']}\n"
                f"å†…å®¹: {e['content']}\n"
                f"{'='*30}"
                for e in events
            ])

            system_prompt = """
ä½ æ˜¯ä¸€ä¸ªåˆæ ¼çš„åª’ä½“æŠ•èµ„ç»ç†ï¼Œéœ€è¦åˆ†æç¤¾äº¤åª’ä½“å†…å®¹å¹¶è¯„ä¼°æŠ•èµ„ä»·å€¼ã€‚è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤åˆ†æï¼š

1. å‘å¸ƒè€…èƒŒæ™¯è¯„ä¼°ï¼š
- åˆ†æå‘å¸ƒè€…çš„èƒŒæ™¯ã€å½±å“åŠ›å’Œå¯ä¿¡åº¦
- è¯„ä¼°å…¶åœ¨åŠ å¯†å¸‚åœºä¸­çš„ä¸“ä¸šæ€§å’Œå£°èª‰

2. å†…å®¹åˆ†æï¼š
- æ£€æŸ¥æ˜¯å¦åŒ…å«å¯éªŒè¯çš„æŠ€æœ¯ä¿¡æ¯
- è¯„ä¼°é¡¹ç›®ç»†èŠ‚å’ŒæŠ€æœ¯å®ç°çš„å¯é æ€§
- åˆ†æä¸å½“å‰å¸‚åœºè¶‹åŠ¿çš„ç›¸å…³æ€§

3. å¸‚åœºçƒ­åº¦åˆ†æï¼š
- è¯„ä¼°å†…å®¹çš„å¸‚åœºåå“
- åˆ†æä¸å½“å‰åŠ å¯†å¸‚åœºè¶‹åŠ¿çš„å…³è”åº¦

4. æŠ•èµ„æ½œåŠ›è¯„ä¼°ï¼š
- ä¸ºæ¯æ¡å†…å®¹æ‰“åˆ†ï¼ˆ1-10åˆ†ï¼‰
- ç»¼åˆè€ƒè™‘å‘å¸ƒè€…èƒŒæ™¯ã€å†…å®¹å¯é æ€§å’Œå¸‚åœºçƒ­åº¦

5. è¾“å‡ºæ ¼å¼ï¼š
- ç­›é€‰å¹¶å±•ç¤ºæœ€å…·æŠ•èµ„ä»·å€¼çš„å‰5æ¡å†…å®¹
- è¯´æ˜æ¯æ¡å†…å®¹çš„å…·ä½“æŠ•èµ„ç†ç”±
- å¦‚æœå†…å®¹å°‘äº5æ¡ï¼Œåˆ™åˆ†ææ‰€æœ‰å¯ç”¨å†…å®¹

è¯·ç”¨ç®€æ´ä¸“ä¸šçš„è¯­è¨€è¾“å‡ºåˆ†æç»“æœã€‚
"""

            user_prompt = f"è¯·åˆ†æè¿‡å»{period}çš„ä»¥ä¸‹Twitteræ´»åŠ¨ï¼š\n{events_text}"

            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                stream=False
            )

            return response.choices[0].message.content

        except Exception as e:
            error_msg = f"ç”Ÿæˆ{period}æ€»ç»“æ—¶å‡ºé”™: {str(e)}"
            logging.error(error_msg)
            return error_msg

    def start_scheduled_summaries(self):
        """å¯åŠ¨å®šæ—¶æ€»ç»“ä»»åŠ¡"""
        def run_schedule():
            while True:
                schedule.run_pending()
                time.sleep(1)

        def generate_and_send_summary(period):
            summary = self.generate_summary(period)
            # æ‰“å°åˆ°æ§åˆ¶å°
            print(f"\n=== {period} å®šæ—¶æ€»ç»“ ===")
            print(f"æ€»ç»“æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} UTC")
            print(summary)
            print("="*50)
            
            # å‘é€åˆ°Telegram
            if self.telegram:
                self.telegram.send_summary(period, summary)

        # è®¾ç½®å®šæ—¶ä»»åŠ¡ - ä½¿ç”¨UTCæ—¶é—´
        schedule.every(30).minutes.do(lambda: generate_and_send_summary('30min'))
        schedule.every(6).hours.do(lambda: generate_and_send_summary('6hour'))
        schedule.every(24).hours.do(lambda: generate_and_send_summary('24hour'))

        threading.Thread(target=run_schedule, daemon=True).start()
        logging.info("å®šæ—¶æ€»ç»“ä»»åŠ¡å·²å¯åŠ¨")

# åˆ›å»ºå¤„ç†å™¨å®ä¾‹
data_processor = TwitterDataProcessor()

@app.route('/webhook/twitter', methods=['POST'])
def webhook_receiver():
    """æ¥æ”¶webhookæ¨é€çš„æ•°æ®å¹¶å¤„ç†"""
    try:
        logging.info("=== æ”¶åˆ°æ–°çš„ Webhook è¯·æ±‚ ===")
        logging.info(f"è¯·æ±‚æ–¹æ³•: {request.method}")
        logging.info(f"è¯·æ±‚å¤´: {dict(request.headers)}")
        logging.info(f"JSON æ•°æ®: {request.json}")
        
        if data_processor.process_webhook_data(request.json):
            return jsonify({
                "status": "success",
                "message": "Data processed and saved",
                "timestamp": datetime.now().isoformat()
            }), 200
        else:
            return jsonify({
                "status": "error",
                "message": "Failed to process data"
            }), 500
            
    except Exception as e:
        logging.error(f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return jsonify({
            "status": "error",
            "message": str(e)
        }), 500

def process_data():
    """å¤„ç†é˜Ÿåˆ—ä¸­çš„æ•°æ®"""
    try:
        summarizer = TwitterSummarizer()
        
        while True:
            try:
                # ä»é˜Ÿåˆ—ä¸­è·å–æ•°æ®
                data = data_queue.get()
                # ä¿å­˜æ•°æ®
                data_processor.process_webhook_data(data)
                
            except Exception as e:
                logging.error(f"å¤„ç†æ•°æ®å¤±è´¥: {str(e)}")
    except Exception as e:
        logging.error(f"åˆå§‹åŒ– TwitterSummarizer å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    # åˆ›å»ºå¹¶å¯åŠ¨æ•°æ®å¤„ç†çº¿ç¨‹
    process_thread = threading.Thread(target=process_data)
    process_thread.daemon = True
    process_thread.start()
    
    # å¯åŠ¨FlaskæœåŠ¡å™¨
    app.run(host='0.0.0.0', port=5000)